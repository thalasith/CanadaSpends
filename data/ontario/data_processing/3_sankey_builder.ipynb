{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sankey Builder\n",
    "\n",
    "This notebook assumes you have done steps 1 and 2 and have created the final_data spreadsheet in order to start building the sankey.json.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Purpose of this notebook is to create the sankey json to feed into the front-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Helper function to build out the sankey data\n",
    "\n",
    "def build_tree(sub_df: pd.DataFrame, cols, value_col=\"value\", root_name=\"Root\", round_to=8):\n",
    "    \"\"\"\n",
    "    Build a nested dict {\"name\": root_name, \"children\":[...]} for Sankey.\n",
    "    - Each row contributes its value to a path formed by non-null labels in `cols`.\n",
    "    - Internal nodes get \"children\"; leaves get {\"name\": ..., \"amount\": ...}.\n",
    "    \"\"\"\n",
    "    def make_node():\n",
    "        return {\"__children\": {}, \"__amount\": 0.0}\n",
    "\n",
    "    root = make_node()\n",
    "\n",
    "    for _, row in sub_df.iterrows():\n",
    "        amt = float(row[value_col])\n",
    "        if not amt:\n",
    "            continue\n",
    "\n",
    "        # Path from chosen columns, skipping nulls\n",
    "        path = []\n",
    "        for c in cols:\n",
    "            val = row.get(c)\n",
    "            if pd.notna(val):\n",
    "                path.append(str(val))\n",
    "\n",
    "        # Accumulate down the trie\n",
    "        node = root\n",
    "        node[\"__amount\"] += amt\n",
    "        for label in path:\n",
    "            if label not in node[\"__children\"]:\n",
    "                node[\"__children\"][label] = make_node()\n",
    "            node = node[\"__children\"][label]\n",
    "            node[\"__amount\"] += amt\n",
    "\n",
    "    # Collapse trie -> Sankey schema\n",
    "    def collapse(node, name):\n",
    "        if node[\"__children\"]:\n",
    "            return {\n",
    "                \"name\": name,\n",
    "                \"children\": [\n",
    "                    collapse(child_node, child_name)\n",
    "                    for child_name, child_node in node[\"__children\"].items()\n",
    "                ],\n",
    "            }\n",
    "        else:\n",
    "            return {\"name\": name, \"amount\": round(node[\"__amount\"], round_to)}\n",
    "\n",
    "    return {\n",
    "        \"name\": root_name,\n",
    "        \"children\": [\n",
    "            collapse(child_node, child_name)\n",
    "            for child_name, child_node in root[\"__children\"].items()\n",
    "        ],\n",
    "    }\n",
    "\n",
    "# ========= Config =========\n",
    "excel_path = Path(\"./processed_data/final_data.xlsx\")  # <-- change if needed\n",
    "sheet_name = \"Sheet1\"\n",
    "value_cols  = [\"2023_24\",\"2024_25\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: ..\\2023_24\\sankey.json\n",
      "Totals: {'revenue': 208.975, 'spending': 209.668, 'total': -0.693000000000012}\n",
      "Wrote: ..\\2024_25\\sankey.json\n",
      "Totals: {'revenue': 226.161, 'spending': 227.251, 'total': -1.0900000000000034}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hierarchy (left -> right). This is the flipped order you asked for:\n",
    "# Category first, then the specific source, then capital/op, then transfer.\n",
    "# You can tweak this list if you want a different grouping precedence.\n",
    "column_order = [\n",
    "    \"sankey_2\",\n",
    "    \"sankey_3\",\n",
    "    \"sankey_4\",\n",
    "]\n",
    "\n",
    "# ========= Load =========\n",
    "for value_col in value_cols:\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "    df[value_col] = pd.to_numeric(df[value_col], errors=\"coerce\").fillna(0)\n",
    "    # Split revenue vs spending\n",
    "    rev_df = df[df[\"sankey_1\"] == \"revenue\"].copy()\n",
    "    exp_df = df[df[\"sankey_1\"] == \"spending\"].copy()\n",
    "    # Build both sides\n",
    "    revenue_data  = build_tree(rev_df, column_order, value_col=value_col, root_name=\"Revenue\")\n",
    "    spending_data = build_tree(exp_df, column_order, value_col=value_col, root_name=\"Spending\")\n",
    "    total_spend = round(float(exp_df[value_col].sum()), 8)\n",
    "    total_revenue = round(float(rev_df[value_col].sum()), 8)\n",
    "\n",
    "    # Compose output\n",
    "    out = {\n",
    "        \"total\":    total_revenue - total_spend,\n",
    "        \"spending\": total_spend,\n",
    "        \"revenue\":  total_revenue,\n",
    "        \"spending_data\": spending_data,\n",
    "        \"revenue_data\":  revenue_data,\n",
    "    }\n",
    "    # ========= Save & Preview =========\n",
    "    out_path = Path(\"../\"+ value_col + \"/sankey.json\")  # rename if you like\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"Wrote:\", out_path)\n",
    "    print(\"Totals:\", {\"revenue\": out[\"revenue\"], \"spending\": out[\"spending\"], \"total\": out[\"total\"]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
